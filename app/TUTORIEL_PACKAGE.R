# ============================================================================
# TUTORIEL COMPLET DU PACKAGE DE CLUSTERING
# Utilisation des fonctions utilisateur (user_functions.R)
# ============================================================================

setwd("C:/Users/Romain_admin/Documents/GitHub/RollerClustR/app")
getwd()
# Chargement des librairies et sources
library(R6)

# Charger tous les fichiers du package
source("ClusterAnalysis_parentclass.R")
source("CAH_class.R")
source("kmeans_class.R")
source("ClustOfVar_class.R")
source("Kprototypes_class.R")
source("wrapper.R")
source("user_functions.R")



# ============================================================================
# PARTIE 1 : CLUSTERING SIMPLE AVEC DONNÃ‰ES NUMÃ‰RIQUES
# ============================================================================

cat("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 1 : Clustering simple sur donnÃ©es numÃ©riques          â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# DonnÃ©es d'exemple : iris (dimensions des fleurs)
data(iris)
X_num <- iris[, 1:4]  # Variables numÃ©riques uniquement

cat("ğŸ“Š DonnÃ©es : iris (150 observations, 4 variables numÃ©riques)\n")
cat("Variables :", paste(names(X_num), collapse = ", "), "\n\n")

# 1.1 Clustering automatique (sÃ©lection auto de l'algorithme)
cat("--- 1.1 Clustering automatique ---\n")
resultat1 <- faire_clustering(X_num, k = 3, method = "auto")
cat("\n")

# 1.2 Forcer l'utilisation de CAH+K-means
cat("--- 1.2 Clustering avec CAH+K-means ---\n")
resultat2 <- faire_clustering(X_num, k = 3, method = "cah_kmeans")
cat("\n")

# 1.3 Afficher un rÃ©sumÃ© dÃ©taillÃ©
cat("--- 1.3 RÃ©sumÃ© dÃ©taillÃ© du clustering ---\n")
resumer_clustering(resultat2)

# ============================================================================
# PARTIE 2 : TROUVER LE NOMBRE OPTIMAL DE CLUSTERS
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 2 : Recherche du nombre optimal de clusters (k)       â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 2.1 Ã‰valuation avec CAH+K-means
cat("--- 2.1 Ã‰valuation de k (de 2 Ã  8) ---\n")
evaluation_k <- trouver_k_optimal(
  X_num, 
  k_min = 2, 
  k_max = 8,
  method = "cah_kmeans",
  afficher_graphique = TRUE  # Mettre TRUE pour voir le graphique
)

cat("\nRÃ©sultats de l'Ã©valuation :\n")
print(evaluation_k)

# Le k optimal est suggÃ©rÃ© automatiquement
cat("\nğŸ’¡ Conseil : Choisir k oÃ¹ le gain d'inertie commence Ã  stagner (mÃ©thode du coude)\n")

# ============================================================================
# PARTIE 3 : ANALYSE DES VARIABLES ILLUSTRATIVES
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 3 : Analyse de variables illustratives                â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# Utiliser le clustering avec k=3
model <- faire_clustering(X_num, k = 3, method = "cah_kmeans")

# 3.1 Analyser la variable Species (qualitative)
cat("--- 3.1 Analyse de la variable Species (qualitative) ---\n")
analyse_species <- analyser_illustratives(
  model, 
  iris[5],  # Species
  afficher = TRUE
)

# 3.2 CaractÃ©risation dÃ©taillÃ©e des groupes
cat("\n\n--- 3.2 CaractÃ©risation dÃ©taillÃ©e avec Species ---\n")
caracteriser_groupes(
  model, 
  iris$Species, 
  "Species",
  mode = "complet"
)

# ============================================================================
# PARTIE 4 : COMPARAISON D'ALGORITHMES
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 4 : Comparaison de plusieurs algorithmes              â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 4.1 Comparer CAH+K-means vs K-means standard 
cat("--- 4.1 Comparaison de 3 algorithmes ---\n")
comparateur <- comparer_algorithmes(
  X_num, 
  k = 3,
  methods = c("cah_kmeans", "kmeans")
)

# 4.2 Afficher les rÃ©sultats de comparaison
cat("\n--- 4.2 RÃ©sultats de la comparaison ---\n")
resultats_comp <- comparateur$compare()

# 4.3 Obtenir un algorithme spÃ©cifique
model_kmeans <- comparateur$get_result("kmeans")
cat("\nğŸ“Œ ModÃ¨le K-means rÃ©cupÃ©rÃ© de la comparaison\n")
model_kmeans$print()

# ============================================================================
# PARTIE 5 : STATISTIQUES PAR GROUPE
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 5 : Statistiques descriptives par groupe              â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 5.1 Calculer les statistiques pour chaque variable
stats <- statistiques_par_groupe(model, X_num, afficher = TRUE)

# 5.2 AccÃ©der aux statistiques d'une variable spÃ©cifique
cat("\n--- 5.2 Statistiques pour Sepal.Length uniquement ---\n")
print(stats$Sepal.Length)

# ============================================================================
# PARTIE 6 : EXPORT DES RÃ‰SULTATS
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 6 : Export des rÃ©sultats                              â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 6.1 Obtenir les groupes
groupes <- obtenir_groupes(model)
cat("--- 6.1 Groupes obtenus ---\n")
cat("Distribution :\n")
print(table(groupes))

# 6.2 Exporter vers un data frame
resultats_df <- exporter_resultats(
  model, 
  iris,  # DonnÃ©es originales
  inclure_donnees = TRUE,
  fichier = "resultats.csv"  # Mettre "resultats.csv" pour sauvegarder
)

cat("\n--- 6.2 AperÃ§u des rÃ©sultats exportÃ©s ---\n")
print(head(resultats_df, 10))

# 6.3 GÃ©nÃ©rer un rapport textuel
cat("\n--- 6.3 Rapport de clustering ---\n")
generer_rapport(model, fichier = "rapport.txt")  # Mettre "rapport.txt" pour sauvegarder

# ============================================================================
# PARTIE 7 : CLUSTERING DE VARIABLES (ClustOfVar)
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 7 : Clustering de VARIABLES (ClustOfVar)              â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

cat("ATTENTION : ClustOfVar fait du clustering sur les VARIABLES, pas les observations!\n\n")

# 7.1 Clustering de variables numÃ©riques
cat("--- 7.1 Clustering des 4 variables d'iris ---\n")
model_var <- faire_clustering(X_num, k = 2, method = "clustofvar")

# 7.2 RÃ©sumÃ© dÃ©taillÃ©
cat("\n--- 7.2 RÃ©sumÃ© du clustering de variables ---\n")
resumer_clustering(model_var)

# 7.3 Groupes de variables
cat("\n--- 7.3 Composition des groupes de variables ---\n")
groupes_var <- obtenir_groupes(model_var)
print(groupes_var)

for (k in 1:2) {
  vars_k <- names(groupes_var)[groupes_var == k]
  cat("Cluster", k, "contient :", paste(vars_k, collapse = ", "), "\n")
}

# 7.4 QualitÃ© des clusters de variables
cat("\n--- 7.4 QualitÃ© des clusters de variables ---\n")
if (inherits(model_var, "ClustOfVar")) {
  qualites <- model_var$qualite_clusters()
  print(qualites)
  
  # Matrice de corrÃ©lations
  cat("\n--- 7.5 Matrice de corrÃ©lations variables/clusters ---\n")
  cor_mat <- model_var$matrice_correlations()
  print(round(cor_mat, 3))
}

# ============================================================================
# PARTIE 8 : WORKFLOW COMPLET AUTOMATISÃ‰
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 8 : Workflow complet automatisÃ©                       â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

cat("ğŸš€ Lancement d'un workflow complet...\n\n")

# 8.1 Workflow tout-en-un
workflow <- clustering_complet(
  data = X_num,
  variables_illustratives = iris[5],  # Species
  k_min = 2,
  k_max = 6,
  k_final = NULL,  # DÃ©tection automatique
  method = "cah_kmeans",
  fichier_resultats = NULL,  # Mettre "workflow_resultats.csv" pour sauvegarder
  fichier_rapport = "workflow_rapport.txt"      # Mettre NULL pour ne pas sauvegarder
)

# 8.2 AccÃ©der aux rÃ©sultats du workflow
cat("\n--- 8.2 Contenu du workflow ---\n")
cat("âœ“ Objet de clustering : disponible\n")
cat("âœ“ Groupes : ", length(workflow$groupes), "observations\n")
cat("âœ“ RÃ©sultats : ", nrow(workflow$resultats), "lignes\n")
cat("âœ“ Ã‰valuation k : ", nrow(workflow$evaluation_k), "valeurs testÃ©es\n")
if (!is.null(workflow$illustratives)) {
  cat("âœ“ Variables illustratives : ", nrow(workflow$illustratives), "analysÃ©es\n")
}

# ============================================================================
# PARTIE 9 : PIPELINE RÃ‰UTILISABLE
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 9 : CrÃ©ation d'un pipeline rÃ©utilisable               â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 9.1 CrÃ©er un pipeline CAH+K-means avec k=3
cat("--- 9.1 CrÃ©ation d'un pipeline CAH+K-means ---\n")
mon_pipeline <- creer_pipeline(
  method = "cah_kmeans",
  k = 3,
  cr = TRUE,
  use_kmeans = TRUE
)

cat("âœ“ Pipeline crÃ©Ã© avec les paramÃ¨tres :\n")
cat("  - MÃ©thode :", attr(mon_pipeline, "method"), "\n")
cat("  - k =", attr(mon_pipeline, "k"), "\n")

# 9.2 Appliquer le pipeline Ã  diffÃ©rents datasets
cat("\n--- 9.2 Application du pipeline ---\n")

# Sur iris
resultat_iris <- mon_pipeline(iris[1:4])
cat("âœ“ Pipeline appliquÃ© sur iris\n")
resultat_iris$print()

# Sur mtcars (autre dataset)
cat("\nâœ“ Pipeline appliquÃ© sur mtcars\n")
data(mtcars)
resultat_mtcars <- mon_pipeline(mtcars[1:7])
resultat_mtcars$print()

# ============================================================================
# PARTIE 10 : DONNÃ‰ES MIXTES (numÃ©riques + catÃ©gorielles)
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  PARTIE 10 : Clustering sur donnÃ©es mixtes                    â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# 10.1 CrÃ©er un dataset mixte
data_mixte <- data.frame(
  age = c(25, 30, 35, 40, 22, 28, 33, 38, 45, 50,
          26, 31, 36, 41, 23, 29, 34, 39, 46, 51),
  salaire = c(30, 40, 50, 60, 28, 38, 48, 58, 70, 80,
              32, 42, 52, 62, 29, 39, 49, 59, 71, 81),
  sexe = factor(rep(c("H", "F", "H", "F"), 5)),
  diplome = factor(rep(c("Bac", "Licence", "Master", "Doctorat"), 5))
)

cat("ğŸ“Š Dataset mixte crÃ©Ã© :\n")
cat("  - 2 variables numÃ©riques : age, salaire\n")
cat("  - 2 variables catÃ©gorielles : sexe, diplome\n")
cat("  - 20 observations\n\n")

# 10.2 Clustering avec ClustOfVar (gÃ¨re le mixte)
cat("--- 10.2 Clustering avec ClustOfVar (gÃ¨re les donnÃ©es mixtes) ---\n")
model_mixte <- faire_clustering(
  data_mixte, 
  k = 2, 
  method = "clustofvar"
)

cat("\n--- 10.3 RÃ©sumÃ© du clustering mixte ---\n")
resumer_clustering(model_mixte)

# ============================================================================
# PARTIE 11 : CLUSTERING SUR DONNÃ‰ES MIXTES AVEC K-PROTOTYPES
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘ Â PARTIE 11 : Test de K-PROTOTYPES (Algorithme pour donnÃ©es mixtes) Â  Â â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# ----------------------------------------------------------------------------
# 11.1 PRÃ‰PARATION DU DATASET MIXTE (Titanic)
# ----------------------------------------------------------------------------
cat("--- 11.1 PrÃ©paration du dataset 'Titanic' ---\n")
library(tidyverse)
# Charger les donnÃ©es (disponibles dans R de base)
data(Titanic)
# Transformer la table de frÃ©quences en un data frame d'observations
data_titanic <- as.data.frame(Titanic) %>%
  uncount(Freq) # CrÃ©e une ligne par observation (1:1)

# SÃ©lectionner les variables et les convertir en facteurs/numÃ©riques

# Solution 1: Conversion explicite des niveaux du facteur
data_mixte_kproto <- data_titanic %>%
  mutate(
    Age = as.factor(Age), 
    Class = as.factor(Class), 
    Sex = as.factor(Sex),
    # Conversion correcte pour Yes/No :
    Survived_Num = as.numeric(Survived == "Yes") 
    # Ceci convertit TRUE/FALSE en 1/0, crÃ©ant une vraie variable numÃ©rique
  ) %>%
  select(Age, Class, Sex, Survived_Num)

# Vous devez vous assurer que Survided_Num est bien de type 'numeric' double
# et non 'integer' dans votre data frame final.

# Vous devez vous assurer que Survided_Num est bien de type 'numeric' double
# et non 'integer' dans votre data frame final.


# On vÃ©rifie les types
print(sapply(data_mixte_kproto, class))
cat(sprintf("\nğŸ“Š Dataset Titanic (mixte) : %d observations, %d variables.\n", 
            nrow(data_mixte_kproto), ncol(data_mixte_kproto)))
cat("Variables catÃ©gorielles : Age, Class, Sex.\n")
cat("Variables numÃ©riques : Survived_Num.\n\n")

# ----------------------------------------------------------------------------
# 11.2 CLUSTERING AVEC LA MÃ‰THODE faire_clustering(method = "kprototypes")
# ----------------------------------------------------------------------------
cat("--- 11.2 Lancement de K-prototypes (k=4) ---\n")

# Note : K-prototypes nÃ©cessite de spÃ©cifier un poids 'lambda' pour les 
# variables numÃ©riques par rapport aux catÃ©gorielles.
# Si votre 'faire_clustering' ne le gÃ¨re pas directement, il faudra ajouter 
# un paramÃ¨tre 'lambda' ou laisser la classe Kprototypes_class utiliser un dÃ©faut.
model_kproto <- faire_clustering(
  data_mixte_kproto, 
  k = 4, # On choisit k=4 (pour les 4 classes de passagers/Ã©quipage)
  method = "kprototypes"
)

print(sapply(data_mixte_kproto, class))
cat("\n--- 11.3 RÃ©sumÃ© du clustering K-prototypes ---\n")
resumer_clustering(model_kproto)


# ----------------------------------------------------------------------------
# 11.4 TEST DE LA MÃ‰THODE $predict() - CLASSIFICATION D'UNE NOUVELLE OBSERVATION
# ----------------------------------------------------------------------------
cat("\n\n--- 11.4 Classification d'une nouvelle observation avec $predict() ---\n")

# CrÃ©ation d'une nouvelle observation fictive
nouvelle_obs <- data.frame(
  Age = factor("Child", levels = levels(data_mixte_kproto$Age)),
  Class = factor("1st", levels = levels(data_mixte_kproto$Class)),
  Sex = factor("Female", levels = levels(data_mixte_kproto$Sex)),
  Survived_Num = 0.5 # Valeur mÃ©diane hypothÃ©tique
)

# Assurer que les niveaux correspondent (trÃ¨s important pour K-prototypes)
# Reconstruire avec les mÃªmes niveaux pour le test :
nouvelle_obs_test <- data.frame(
  Age = factor("Child", levels = levels(data_mixte_kproto$Age)),
  Class = factor("1st", levels = levels(data_mixte_kproto$Class)),
  Sex = factor("Female", levels = levels(data_mixte_kproto$Sex)),
  Survived_Num = 0.5
)

# Si la mÃ©thode $predict(X) renvoie simplement l'affectation du groupe :
if (inherits(model_kproto, "Kprototypes")) {
  # Assurez-vous que la mÃ©thode est bien implÃ©mentÃ©e dans Kprototypes_class.R
  # Et qu'elle accepte un nouveau data.frame X pour la prÃ©diction
  tryCatch({
    prediction_groupe <- model_kproto$predict(nouvelle_obs_test)
    cat(sprintf("âœ“ Nouvelle observation affectÃ©e au Groupe : %s\n", prediction_groupe))
  }, error = function(e) {
    cat(sprintf("âŒ Erreur lors du test de $predict() : %s\n", e$message))
    cat("Note : La mÃ©thode $predict() pour K-prototypes doit gÃ©rer l'affectation de nouvelles donnÃ©es.\n")
  })
}


# ----------------------------------------------------------------------------
# 11.5 TEST DE L'Ã‰VALUATION DU K OPTIMAL (Applicable aux observations)
# ----------------------------------------------------------------------------
cat("\n\n--- 11.5 Recherche du k optimal pour K-prototypes (3 Ã  6) ---\n")

# K-prototypes utilise des mÃ©triques diffÃ©rentes (coÃ»t global)
# Si trouver_k_optimal() est bien implÃ©mentÃ© pour Kprototypes (en utilisant 
# le coÃ»t des prototypes), il devrait fonctionner :

tryCatch({
  evaluation_k_kproto <- trouver_k_optimal(
    data_mixte_kproto, 
    k_min = 3, 
    k_max = 6,
    method = "kprototypes",
    afficher_graphique = TRUE # Afficher le graphique pour l'inertie/le coÃ»t
  )

  cat("\nRÃ©sultats de l'Ã©valuation du coÃ»t :\n")
  print(evaluation_k_kproto)

}, error = function(e) {
  cat(sprintf("âŒ Erreur lors de l'Ã©valuation de k : %s\n", e$message))
  cat("Note : Assurez-vous que 'trouver_k_optimal' gÃ¨re la mÃ©trique de coÃ»t pour K-prototypes.\n")
})


# ----------------------------------------------------------------------------
# 11.6 CARACTÃ‰RISATION DES GROUPES (VARIABLES MIXTES)
# ----------------------------------------------------------------------------
cat("\n\n--- 11.6 CaractÃ©risation des groupes K-prototypes ---\n")

# La caractÃ©risation doit afficher :
# - Moyennes (pour Survived_Num)
# - Distribution des frÃ©quences (pour Age, Class, Sex)

# On utilise la variable 'Class' de la source de donnÃ©es pour l'analyse illustrative
var_illus_qual <- data_mixte_kproto$Class
nom_var_illus <- "Class_Ticket"

caracteriser_groupes(
  model_kproto, 
  var_illus_qual, 
  nom_var_illus,
  mode = "complet"
)

cat("\n--- FIN DU TEST K-PROTOTYPES ---\n")


# ============================================================================
# RÃ‰SUMÃ‰ DES FONCTIONS UTILISATEUR DISPONIBLES
# ============================================================================

cat("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  RÃ‰SUMÃ‰ DES FONCTIONS UTILISATEUR DISPONIBLES                 â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

cat("ğŸ“š FONCTIONS PRINCIPALES :\n\n")

cat("1ï¸âƒ£  faire_clustering()
   â†’ Clustering simplifiÃ© avec sÃ©lection automatique d'algorithme
   â†’ ParamÃ¨tres : data, k, method ('auto', 'cah_kmeans', 'kmeans', 'clustofvar')
   
2ï¸âƒ£  trouver_k_optimal()
   â†’ Recherche du nombre optimal de clusters
   â†’ Teste plusieurs valeurs de k et affiche le graphique du coude
   
3ï¸âƒ£  analyser_illustratives()
   â†’ Analyse de variables illustratives via predict()
   â†’ Retourne indicateurs de liaison (rapport corrÃ©lation, V de Cramer)
   
4ï¸âƒ£  caracteriser_groupes()
   â†’ CaractÃ©risation dÃ©taillÃ©e des groupes avec une variable
   â†’ Mode 'complet' ou 'rapide'
   
5ï¸âƒ£  comparer_algorithmes()
   â†’ Comparaison de plusieurs algorithmes sur les mÃªmes donnÃ©es
   â†’ Calcule les matrices de confusion et taux d'accord
   
6ï¸âƒ£  obtenir_groupes()
   â†’ Extrait le vecteur des affectations aux groupes
   
7ï¸âƒ£  exporter_resultats()
   â†’ Export vers data frame ou fichier CSV
   â†’ Peut inclure les donnÃ©es originales
   
8ï¸âƒ£  visualiser_clustering()
   â†’ Visualisations adaptÃ©es selon l'algorithme
   â†’ Dendrogramme pour CAH, heatmap pour ClustOfVar
   
9ï¸âƒ£  resumer_clustering()
   â†’ RÃ©sumÃ© dÃ©taillÃ© avec statistiques spÃ©cifiques
   â†’ Inertie, homogÃ©nÃ©itÃ© selon l'algorithme
   
ğŸ”Ÿ statistiques_par_groupe()
   â†’ Statistiques descriptives pour chaque groupe
   â†’ Moyenne, Ã©cart-type, min, max pour variables numÃ©riques
   
1ï¸âƒ£1ï¸âƒ£ generer_rapport()
   â†’ Rapport textuel complet
   â†’ Sauvegarde optionnelle dans un fichier
   
1ï¸âƒ£2ï¸âƒ£ clustering_complet()
   â†’ Workflow tout-en-un automatisÃ©
   â†’ Recherche k optimal + clustering + analyse + export
   
1ï¸âƒ£3ï¸âƒ£ creer_pipeline()
   â†’ Pipeline rÃ©utilisable avec paramÃ¨tres fixÃ©s
   â†’ Application Ã  diffÃ©rents datasets\n")

cat("\n")
cat("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘  ğŸ‰ FIN DU TUTORIEL - Package de Clustering R6                â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")
