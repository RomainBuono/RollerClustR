---
title: "Introduction to RollerClustR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to RollerClustR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(RollerClustR)
```

## Overview

**RollerClustR** is an R package that provides advanced clustering algorithms specifically designed to group **variables** (not observations). This approach is particularly useful for:

- Reducing dimensionality by identifying groups of redundant variables
- Understanding the correlation structure of a dataset
- Creating synthetic variables representative of variable groups
- Identifying latent dimensions in the data

## Three Clustering Methods

RollerClustR provides three complementary algorithms:

### 1. VAR_CAH: Hierarchical Agglomerative Clustering

A **bottom-up** approach that progressively merges the most similar variables.

**Advantages:**
- Complete dendrogram allowing exploration of different numbers of clusters
- Based on correlation, easy to interpret
- Robust and deterministic

**When to use:**
- For initial data exploration
- When you want to visualize the hierarchy of variables
- For continuous numeric data

### 2. VAR_KMEANS: K-Means Variable Clustering

An **iterative reallocation** approach that optimizes cluster assignments by minimizing within-cluster inertia.

**Advantages:**
- Explicitly optimizes within-cluster inertia (quantitative criterion)
- Multiple random initializations for robustness
- Fast convergence (typically < 20 iterations)
- Predict method for assigning new variables to clusters

**When to use:**
- When K (number of clusters) is known in advance
- When optimality of the partition is important
- For large datasets (faster than hierarchical methods)
- When you need to predict cluster membership for new variables

### 3. TandemVarClust: Tandem Clustering for Mixed Data

A **Tandem** approach combining Multiple Correspondence Analysis (MCA) with Hierarchical Agglomerative Clustering (HAC) on modalities.

**Advantages:**
- Specialized for mixed data (quantitative and categorical)
- Clustering at the modality level (finer than variable level)
- Automatic discretization of continuous variables
- Assignment of observations to clusters via Dice index

**When to use:**
- For categorical or mixed data
- When you need to analyze illustrative variables
- For surveys or qualitative data
- When you want to capture fine structures at the modality level

## Basic Usage

### Simple Method: Wrapper Function

The easiest way to use RollerClustR is via the `roller_clust()` function:

```{r basic_usage}
# Load iris data
data(iris)

# Clustering with VAR_CAH
result <- roller_clust(
  X = iris[, 1:4],
  method = "var_cah",
  K = 2,
  scale = TRUE
)

# Display summary
result$summary()

# Access groups
print(result$Groupes)
```

### Advanced Method: R6 Classes

For more control, use R6 classes directly:

```{r r6_usage}
# Create a VAR_CAH object
model <- VAR_CAH$new(K = 2, scale = TRUE)

# Fit on data
model$fit(iris[, 1:4])

# Display summary
model$summary()

# Modify number of clusters
model$K <- 3
```

## Complete Example: Iris Dataset Analysis

### Step 1: Initial Exploration

```{r iris_exploration}
# View data structure
str(iris[, 1:4])

# Correlation matrix
cor(iris[, 1:4])
```

### Step 2: Clustering with Different Methods

```{r iris_clustering}
# Method 1: VAR_CAH (hierarchical)
model_cah <- roller_clust(iris[, 1:4], method = "var_cah", K = 2)
cat("\n=== VAR_CAH ===\n")
print(model_cah$Groupes)

# Method 2: VAR_KMEANS (iterative optimization)
model_kmeans <- roller_clust(
  X = iris[, 1:4], 
  method = "var_kmeans", 
  K = 2,
  n_init = 10  # 10 random initializations for robustness
)
cat("\n=== VAR_KMEANS ===\n")
print(model_kmeans$Groupes)
cat("Within-cluster inertia:", model_kmeans$WithinClusterInertia, "\n")
cat("Converged:", model_kmeans$Converged, "\n")
cat("Iterations:", model_kmeans$NIterations, "\n")
```

### Step 3: Results Comparison

```{r iris_comparison}
# Compare assignments
comparison <- data.frame(
  Variable = names(iris[, 1:4]),
  VAR_CAH = model_cah$Groupes,
  VAR_KMEANS = model_kmeans$Groupes
)
print(comparison)

# Agreement between methods
cat("\nContingency table:\n")
print(table(model_cah$Groupes, model_kmeans$Groupes))
```

## VAR_KMEANS: Optimizing Cluster Quality

VAR_KMEANS is particularly useful when you want to optimize the quality of the partition:

```{r kmeans_optimization}
# Compare different numbers of initializations
results <- data.frame(
  n_init = c(1, 5, 10, 20),
  inertia = numeric(4),
  iterations = numeric(4)
)

for (i in 1:4) {
  model <- roller_clust(
    iris[, 1:4], 
    method = "var_kmeans", 
    K = 2,
    n_init = results$n_init[i]
  )
  results$inertia[i] <- model$WithinClusterInertia
  results$iterations[i] <- model$NIterations
}

print(results)
cat("\nNote: More initializations generally lead to better (lower) inertia\n")
```

## Example with Mixed Data: Iris with Categorical Variables

```{r iris_mixed_example}
# Create mixed data from iris
iris_mixed <- iris
iris_mixed$Size <- cut(iris$Sepal.Length, 
                       breaks = 3, 
                       labels = c("Small", "Medium", "Large"))
iris_mixed$PetalSize <- cut(iris$Petal.Length,
                             breaks = 3,
                             labels = c("Short", "Medium", "Long"))

# Select numeric and categorical variables
data_mixed <- iris_mixed[, c("Sepal.Width", "Petal.Width", "Size", "PetalSize")]

# Use TandemVarClust for mixed data
model_tandem <- roller_clust(
  X = data_mixed,
  method = "tandem",
  K = 2,
  n_bins = 3
)

cat("\n=== TandemVarClust - Modality Clustering ===\n")
print(model_tandem$Groupes)

cat("\n=== Summary by Original Variable ===\n")
print(model_tandem$get_variable_summary())
```

## Illustrative Variable Analysis with TandemVarClust

TandemVarClust allows analyzing illustrative variables to understand their association with clusters:

```{r tandem_predict}
# After fitting the model, analyze Species as an illustrative variable
model_tandem <- TandemVarClust$new(K = 2, n_bins = 3)
model_tandem$fit(data_mixed)

# Analyze Species association with clusters
results <- model_tandem$predict(newdata = data.frame(Species = iris$Species))

cat("\n=== Species Association with Clusters ===\n")
cat("Cramer's V:", results$Species$cramers_v, "\n")
cat("p-value (Chi²):", results$Species$chi2_test$p.value, "\n")
cat("Significant association:", results$Species$significant, "\n")

# Contingency table
cat("\nContingency table:\n")
print(results$Species$contingency)
```

## Predicting Cluster Membership for New Variables

VAR_KMEANS and VAR_CAH both provide a `predict()` method to assign new variables to existing clusters:

```{r predict_example}
# Fit model on iris data
model <- roller_clust(iris[, 1:4], method = "var_kmeans", K = 2, n_init = 10)

# Create a new variable (linear combination)
new_var <- data.frame(
  NewVariable = iris$Sepal.Length + iris$Petal.Length
)

# Predict cluster assignment
prediction <- model$predict(new_var)

cat("New variable assigned to cluster:", prediction$NewVariable$cluster, "\n")
cat("Correlation with cluster center:", prediction$NewVariable$best_score, "\n")
cat("\nScores with all clusters:\n")
print(prediction$NewVariable$scores)
```

## Advanced Features

### Dynamic K Modification

```{r dynamic_k}
# Create a model with K=2
model <- VAR_CAH$new(K = 2)
model$fit(iris[, 1:4])

cat("With K=2:\n")
print(model$Groupes)

# Change K (automatically refits)
model$K <- 3

cat("\nAfter modification to K=3:\n")
print(model$Groupes)
```

### Dynamic K Modification for VAR_KMEANS

```{r dynamic_k_kmeans,eval=FALSE}
# VAR_KMEANS also supports dynamic K modification
model_kmeans <- VAR_KMEANS$new(K = 2, n_init = 10)
model_kmeans$fit(iris[, 1:4])

cat("With K=2:\n")
print(model_kmeans$Groupes)
cat("Inertia:", model_kmeans$WithinClusterInertia, "\n\n")

# Change K
model_kmeans$K <- 3

cat("After modification to K=3:\n")
print(model_kmeans$Groupes)
cat("Inertia:", model_kmeans$WithinClusterInertia, "\n")
```

### K Modification for TandemVarClust

```{r dynamic_k_tandem}
# TandemVarClust uses refit_with_k() to change K
model_tandem <- TandemVarClust$new(K = 2, n_bins = 3)
model_tandem$fit(data_mixed)

cat("With K=2:\n")
cat("Number of clusters:", model_tandem$K, "\n")

# Change K
model_tandem$refit_with_k(3)

cat("\nAfter refit_with_k(3):\n")
cat("Number of clusters:", model_tandem$K, "\n")
```

### Missing Value Handling

```{r na_handling}
# Create data with NA
iris_na <- iris[, 1:4]
iris_na[1:5, 1] <- NA

# Option 1: Warning (default)
model_warn <- roller_clust(iris_na, na.action = "warn")

# Option 2: Remove observations with NA
model_omit <- roller_clust(iris_na, na.action = "omit")

# Option 3: Stop if NA
# model_fail <- roller_clust(iris_na, na.action = "fail")  # Generates error
```

## Choosing the Optimal Number of Clusters

### Using VAR_KMEANS with Multiple K Values

```{r optimal_k_kmeans}
# Test different values of K
k_values <- 2:4
inertias <- numeric(length(k_values))

for (i in seq_along(k_values)) {
  model <- roller_clust(
    iris[, 1:4], 
    method = "var_kmeans", 
    K = k_values[i],
    n_init = 10
  )
  inertias[i] <- model$WithinClusterInertia
}

# Create results table
results_k <- data.frame(
  K = k_values,
  Inertia = round(inertias, 4)
)
print(results_k)

# Plot elbow curve
plot(k_values, inertias, type = "b", 
     main = "Elbow Method for Optimal K",
     xlab = "Number of Clusters (K)", 
     ylab = "Within-Cluster Inertia",
     col = "blue", pch = 19)
```

## Interpreting Results

### For VAR_CAH and VAR_KMEANS

Variables in the same cluster are highly correlated with each other. Each cluster can be represented by a **synthetic variable** calculated as the first principal component of the cluster.

**Interpretation Example:**
```{r interpretation}
model <- VAR_KMEANS$new(K = 2, n_init = 10)
model$fit(iris[, 1:4])

# Display clusters
cat("Cluster assignments:\n")
for (k in 1:model$K) {
  vars <- model$get_cluster_variables(k)
  cat("Cluster", k, ":", paste(vars, collapse = ", "), "\n")
}

# Interpretation: 
# - If Cluster 1 contains: Sepal.Length, Sepal.Width
#   → These variables measure the "Sepal" dimension
# - If Cluster 2 contains: Petal.Length, Petal.Width
#   → These variables measure the "Petal" dimension
```

### Comparing VAR_CAH and VAR_KMEANS

```{r comparison_methods}
# Fit both methods
cah <- VAR_CAH$new(K = 2, scale = TRUE)
cah$fit(iris[, 1:4])

kmeans <- VAR_KMEANS$new(K = 2, n_init = 20, scale = TRUE)
kmeans$fit(iris[, 1:4])

# Compare results
cat("VAR_CAH clusters:\n")
print(cah$Groupes)

cat("\nVAR_KMEANS clusters:\n")
print(kmeans$Groupes)

cat("\nVAR_KMEANS specific metrics:\n")
cat("Within-cluster inertia:", kmeans$WithinClusterInertia, "\n")
cat("Homogeneity:", kmeans$FHomogeneite, "\n")
cat("Converged:", kmeans$Converged, "\n")

# Agreement
cat("\nAgreement between methods:\n")
print(table(CAH = cah$Groupes, KMEANS = kmeans$Groupes))
```

### For TandemVarClust

TandemVarClust works at the **modality level** (categories of categorical variables and discretized intervals of continuous variables). Modalities in the same cluster have similar profiles in the factorial space derived from MCA.

**Interpretation:**

1. **Modality Clusters**: Each cluster groups modalities (e.g., "Size.Small", "PetalSize.Short", "Sepal.Width.bin1")

2. **Variable Summary**: The `get_variable_summary()` method aggregates results at the original variable level:
   - **cluster_principal**: Cluster containing the majority of the variable's modalities
   - **purity**: Proportion of modalities in the principal cluster (1.0 = all modalities in the same cluster)

3. **Illustrative Variables**: The `predict()` method analyzes the association between a categorical variable and clusters via:
   - **Cramer's V**: Measures association intensity (0 to 1)
   - **Chi-square test**: Tests association significance
   - **Contingency tables**: Distribution of modalities across clusters

**Interpretation Example:**
```{r tandem_interpretation}
model_tandem <- TandemVarClust$new(K = 2, n_bins = 3)
model_tandem$fit(data_mixed)

# Variable summary
summary <- model_tandem$get_variable_summary()
print(summary)

# Interpretation:
# - If "Size" has purity = 1.0 and cluster_principal = 1
#   → All Size modalities (Small, Medium, Large) are in cluster 1
#   → Homogeneous variable
# 
# - If "Sepal.Width" has purity = 0.67 and cluster_principal = 2
#   → 67% of Sepal.Width bins are in cluster 2
#   → More dispersed variable across clusters
```

## Practical Tips

1. **Start with VAR_CAH** for initial exploration of numeric data
2. **Use VAR_KMEANS** when K is known and you want to optimize the partition
3. **Compare VAR_CAH and VAR_KMEANS** to validate structure
4. **Use TandemVarClust** for mixed data (quantitative + categorical)
5. **Standardize** (`scale = TRUE`) if variables have different scales
6. **Try multiple K values** to identify optimal number of clusters using the elbow method
7. **For VAR_KMEANS**:
   - Use `n_init = 20` or more for critical analyses (more robust)
   - Check `Converged = TRUE` to ensure algorithm converged
   - Lower `WithinClusterInertia` indicates better clustering
8. **Always examine** the correlation matrix first (for VAR_CAH/VAR_KMEANS)
9. **For TandemVarClust**:
   - Adjust `n_bins` according to desired granularity for continuous variables
   - Use `n_factors` to control the number of retained factorial axes
   - Analyze variance explained by axes: `model$VarianceExplained`

## Comparison of Three Methods

| Criterion | VAR_CAH | VAR_KMEANS | TandemVarClust |
|-----------|---------|------------|----------------|
| **Data Type** | Numeric | Numeric | Mixed (numeric + categorical) |
| **Approach** | Agglomerative (bottom-up) | Iterative reallocation | Tandem (MCA + HAC) |
| **Clustering Unit** | Variables | Variables | Modalities |
| **Number of Clusters** | Fixed in advance (K) | Fixed in advance (K) | Fixed in advance (K) |
| **Optimization** | No explicit criterion | Minimizes within-cluster inertia | No explicit criterion |
| **Initialization** | Deterministic | Multiple random (n_init) | Deterministic |
| **Convergence** | N/A | Yes (typically < 20 iter) | N/A |
| **Visualization** | Dendrogram | Elbow curve | Modality dendrogram |
| **Prediction** | Via predict() | Via predict() | Via predict() with statistical tests |
| **Speed** | Medium | Fast | Slow |
| **Complexity** | Simple | Simple-Medium | High |

## Workflow Recommendations

### For Numeric Data Analysis

```{r workflow_numeric, eval=FALSE}
# Step 1: Initial exploration with VAR_CAH
model_cah <- roller_clust(data, method = "var_cah", K = 3)
model_cah$summary()

# Step 2: Determine optimal K with VAR_KMEANS
k_test <- 2:6
for (k in k_test) {
  model <- roller_clust(data, method = "var_kmeans", K = k, n_init = 20)
  cat("K =", k, ": Inertia =", model$WithinClusterInertia, "\n")
}

# Step 3: Refine with VAR_KMEANS (optimal K)
model_final <- roller_clust(data, method = "var_kmeans", K = 3, n_init = 50)

# Step 4: Validate by comparing methods
table(model_cah$Groupes, model_final$Groupes)
```

### For Mixed Data Analysis

```{r workflow_mixed, eval=FALSE}
# Step 1: Use TandemVarClust
model_tandem <- roller_clust(
  data_mixed, 
  method = "tandem", 
  K = 3,
  n_bins = 3
)

# Step 2: Analyze variable summary
summary <- model_tandem$get_variable_summary()
print(summary)

# Step 3: Test illustrative variables
results <- model_tandem$predict(newdata = illustrative_data)

# Step 4: Interpret associations
for (var in names(results)) {
  cat("\n", var, ":\n")
  cat("  Cramer's V:", results[[var]]$cramers_v, "\n")
  cat("  Significant:", results[[var]]$significant, "\n")
}
```

## Going Further

- Consult class documentation: `?VAR_CAH`, `?VAR_KMEANS`, `?TandemVarClust`
- Explore additional arguments: `?roller_clust`
- Report bugs on GitHub: https://github.com/yourusername/RollerClustR/issues

## References

- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*
- MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. *Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability*, 1(14), 281-297.
- Chavent, M., Kuentz-Simonet, V., Labenne, A., & Saracco, J. (2012). ClustOfVar: An R package for the clustering of variables. *Journal of Statistical Software*, 50(13), 1-16.
- Escofier, B. (1979). Traitement simultané de variables quantitatives et qualitatives. *Les Cahiers de l'Analyse des Données*, IV(2), 137-146.
- Pagès, J. (2004). Analyse factorielle de données mixtes. *Revue de Statistique Appliquée*, 52(4), 93-111.
- Dice, L. R. (1945). Measures of the amount of ecologic association between species. *Ecology*, 26(3), 297-302.
